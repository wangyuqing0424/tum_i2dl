{"cells":[{"cell_type":"markdown","metadata":{"id":"87a5CqMuqhg3"},"source":["# Simple Classifier / Logistic Regression\n","\n","After having worked with the dataloading part last week, we want to start this week to take a more detailed look into how the training process looks like. So far, our tools are limited and we must restrict ourselves to a simplified model. But nevertheless, this gives us the opportunity to look at the different parts of the training process in more detail and builds up a good base when we turn to more complicated model architectures in the next exercises. \n","\n","This notebook will demonstrate a simple logistic regression model predicting whether a house is ```low-priced``` or ```expensive```. The data that we will use here is the HousingPrice dataset. Feeding some features in our classifier, the output should then be a score that determines in which category the considered house is.\n","\n","![classifierTeaser](images/classifierTeaser.png)"]},{"cell_type":"markdown","metadata":{"id":"nuPFQgYtqhg8"},"source":["Before we start, let us first import some libraries and code that we will need along the way. "]},{"cell_type":"markdown","metadata":{"id":"H8sSJ8Fsqhg8"},"source":["## (Optional) Mount folder in Colab\n","\n","Uncomment thefollowing cell to mount your gdrive if you are using the notebook in google colab:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrycAPQdqhg9","executionInfo":{"status":"ok","timestamp":1668284235812,"user_tz":-60,"elapsed":23393,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"1c54d93a-0a2d-4de3-b499-6aa915c467e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","['1_simple_classifier.ipynb', '__init__.py', 'exercise_code', 'housing_data_preprocessing(optional).ipynb', 'images']\n"]}],"source":["# Use the following lines if you want to use Google Colab\n","# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n","# NOTE: terminate all other colab sessions that use GPU!\n","# NOTE 2: Make sure the correct exercise folder (e.g exercise_04) is given.\n","\n","\n","from google.colab import drive\n","import os\n","\n","gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_04'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present\n","print(sorted(os.listdir()))\n"]},{"cell_type":"code","execution_count":2,"metadata":{"pycharm":{"name":"#%%\n"},"id":"TulfbMo5qhg-","executionInfo":{"status":"ok","timestamp":1668284240882,"user_tz":-60,"elapsed":5075,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}}},"outputs":[],"source":["from exercise_code.data.csv_dataset import CSVDataset\n","from exercise_code.data.csv_dataset import FeatureSelectorAndNormalizationTransform\n","from exercise_code.data.dataloader import DataLoader\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import seaborn as sns\n","\n","\n","pd.options.mode.chained_assignment = None  # default='warn'\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"PS4NZB7Kqhg_"},"source":["## 0. Dataloading and Data Preprocessing\n","\n","Let us load the data that we want to use for our training. The method `get_housing_data()` is providing you with a training, validation and test set that is ready to use.\n","\n","For more information about how to prepare the data and what the final data look like, you can have a look at the notebook `housing_data_preprocessing(optional).ipynb `. We reduced our data and the remaining houses in our dataset are now either labeled with ```1``` and hence categorized as ```expensive```, or they are labeled with ```0``` and hence categorized as ```low-priced```.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"LEmcBz6gqhhA","executionInfo":{"status":"ok","timestamp":1668284247467,"user_tz":-60,"elapsed":6590,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"95ff6cc6-c7eb-48f6-f75b-72f8606a2481"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/i2dl/exercise_04/exercise_code/networks/utils.py:69: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  mn, mx, mean = df.min(), df.max(), df.mean()\n"]},{"output_type":"stream","name":"stdout","text":["You successfully loaded your data! \n","\n","train data shape: (533, 1)\n","train targets shape: (533, 1)\n","val data shape: (167, 1)\n","val targets shape: (167, 1)\n","test data shape: (177, 1)\n","test targets shape: (177, 1) \n","\n","The original dataset looks as follows:\n"]},{"output_type":"execute_result","data":{"text/plain":["      Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","529  530          20       RL          NaN    32668   Pave   NaN      IR1   \n","491  492          50       RL         79.0     9490   Pave   NaN      Reg   \n","459  460          50       RL          NaN     7015   Pave   NaN      IR1   \n","279  280          60       RL         83.0    10005   Pave   NaN      Reg   \n","655  656         160       RM         21.0     1680   Pave   NaN      Reg   \n","\n","    LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n","529         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","491         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n","459         Bnk    AllPub  ...        0    NaN    NaN         NaN       0   \n","279         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","655         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","\n","    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n","529      3   2007        WD         Alloca     200624  \n","491      8   2006        WD         Normal     133000  \n","459      7   2009        WD         Normal     110000  \n","279      3   2008        WD         Normal     192000  \n","655      3   2010        WD         Family      88000  \n","\n","[5 rows x 81 columns]"],"text/html":["\n","  <div id=\"df-aa629766-438a-4b0a-91ef-bc01abc08950\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>MSSubClass</th>\n","      <th>MSZoning</th>\n","      <th>LotFrontage</th>\n","      <th>LotArea</th>\n","      <th>Street</th>\n","      <th>Alley</th>\n","      <th>LotShape</th>\n","      <th>LandContour</th>\n","      <th>Utilities</th>\n","      <th>...</th>\n","      <th>PoolArea</th>\n","      <th>PoolQC</th>\n","      <th>Fence</th>\n","      <th>MiscFeature</th>\n","      <th>MiscVal</th>\n","      <th>MoSold</th>\n","      <th>YrSold</th>\n","      <th>SaleType</th>\n","      <th>SaleCondition</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>529</th>\n","      <td>530</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>NaN</td>\n","      <td>32668</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2007</td>\n","      <td>WD</td>\n","      <td>Alloca</td>\n","      <td>200624</td>\n","    </tr>\n","    <tr>\n","      <th>491</th>\n","      <td>492</td>\n","      <td>50</td>\n","      <td>RL</td>\n","      <td>79.0</td>\n","      <td>9490</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>MnPrv</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>2006</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>133000</td>\n","    </tr>\n","    <tr>\n","      <th>459</th>\n","      <td>460</td>\n","      <td>50</td>\n","      <td>RL</td>\n","      <td>NaN</td>\n","      <td>7015</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Bnk</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>2009</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>110000</td>\n","    </tr>\n","    <tr>\n","      <th>279</th>\n","      <td>280</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>83.0</td>\n","      <td>10005</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>192000</td>\n","    </tr>\n","    <tr>\n","      <th>655</th>\n","      <td>656</td>\n","      <td>160</td>\n","      <td>RM</td>\n","      <td>21.0</td>\n","      <td>1680</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Family</td>\n","      <td>88000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 81 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa629766-438a-4b0a-91ef-bc01abc08950')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aa629766-438a-4b0a-91ef-bc01abc08950 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aa629766-438a-4b0a-91ef-bc01abc08950');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["from exercise_code.networks.utils import *\n","\n","X_train, y_train, X_val, y_val, X_test, y_test, train_dataset = get_housing_data()\n","\n","print(\"train data shape:\", X_train.shape)\n","print(\"train targets shape:\", y_train.shape)\n","print(\"val data shape:\", X_val.shape)\n","print(\"val targets shape:\", y_val.shape)\n","print(\"test data shape:\", X_test.shape)\n","print(\"test targets shape:\", y_test.shape, '\\n')\n","\n","print('The original dataset looks as follows:')\n","train_dataset.df.head()"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"q07awRWuqhhB"},"source":["The data is now ready and can be used to train our classifier model."]},{"cell_type":"markdown","metadata":{"id":"1rkMQE3HqhhB"},"source":["## 1. Set up a Classifier Model\n","\n","Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times (D+1)}$ be our data with $N$ samples and $D$ feature dimensions (+1 for the bias). With our classifier model, we want to predict binary labels $\\mathbf{\\hat{y}} \\in \\mathbb{R}^{N\\times 1}$. Our classifier model should be of the form\n","\n","$$ \\mathbf{\\hat{y}}  = \\sigma \\left( \\mathbf{X} \\cdot \\mathbf{w} \\right), $$ \n","\n","$ $ where $\\mathbf{w}\\in \\mathbb{R}^{(D+1) \\times 1}$ is the weight matrix of our model.\n","\n","The **sigmoid function** $\\sigma: \\mathbb{R} \\to [0, 1]$, defined by \n","\n","$$ \\sigma(t) = \\frac{1}{1+e^{-t}} $$\n","\n","is used to squash the outputs of the linear layer into the interval $[0, 1]$. What we call \"Saturation\". Remember that the sigmoid function is a real-valued function. When applying it on a vector, the sigmoid is operating component-wise.\n","\n","The output of the sigmoid function can be seen as the probability that our sample is indicating a house that can be categorized as ```expensive```. As the probability gets closer to 1, our model is more confident that the input sample is in the class ```expensive```.\n","\n","<img src=\"https://miro.medium.com/max/2400/1*RqXFpiNGwdiKBWyLJc_E7g.png\" width=\"800\">"]},{"cell_type":"markdown","metadata":{"id":"x7X3m8BnqhhC"},"source":["<div class=\"alert alert-success\">\n","    <h3>Task: Check Code</h3>\n","    <p>Take a look at the implementation of the <code>Classifier</code> class in <code>exercise_code/networks/classifier.py</code>. To create a <code>Classifier</code> object, you need to define the number of features that our classifier model takes as input.</p>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"WT0XanqLqhhC"},"source":["## 2. Loss: Binary Cross Entropy\n","\n","For a binary classification like our task, we use a loss function called Binary Cross-Entropy (BCE).\n","\n","$$BCE(y,\\hat{y}) =- \\frac{1}{n} \\sum_{i = 1}^N y_i \\cdot log(\\hat y_i ) - (1- y_i) \\cdot log(1-\\hat y_i) $$\n","\n","where $y\\in\\mathbb{R}$ is the ground truths vector and $\\hat y\\in\\mathbb{R}$ is the vector of predicted probabilities of the houses being expensive.\n","\n","Since the BCE function is a non-convex function, there is no closed-form solution for the optimal weights vector. In order to find the optimal parameters for our model, we need to use numeric methods such as Gradient Descent. But let us have a look at that later. First, you have to complete your first task:"]},{"cell_type":"markdown","metadata":{"id":"S_SFZwZWqhhD"},"source":["<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>In <code>exercise_code/networks/loss.py</code> complete the implementation of the BCE loss function. You need to write the forward and backward pass of BCE as <code>forward()</code> and <code>backward()</code> function. The backward pass of the loss is needed to later optimize your weights of the model. You can test your implementation by the included testing code in the cell below.</p>\n","</div>"]},{"cell_type":"code","execution_count":4,"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"cZ_eT-3pqhhD","executionInfo":{"status":"ok","timestamp":1668284251328,"user_tz":-60,"elapsed":3867,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"a3938369-60f1-4f96-ae4c-183abfa02e2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["BCEForwardTest passed.\n","BCEBackwardTest passed.\n","Congratulations you have passed all the unit tests!!! Tests passed: 2/2\n"]}],"source":["from exercise_code.tests.loss_tests import *\n","from exercise_code.networks.loss import BCE\n","\n","bce_loss = BCE()\n","res = BCETest(bce_loss)()"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"BYkvcxhTqhhE"},"source":["## 3. Backpropagation\n","\n","The backpropagation algorithm allows the information from the loss flowing backward through the network in order to compute the gradient of the loss function $L$ w.r.t the weights $w$ of the model. \n","\n","The key idea of backpropagation is decomposing the derivatives by applying the chain rule to the loss function.\n","\n","$$ \\frac{\\partial L(w)}{\\partial w} = \\frac{\\partial L(w)}{\\partial \\hat y} \\cdot \\frac{\\partial \\hat y}{\\partial w}$$\n","\n","You have already completed the `forward()` and `backward()` pass of the loss function, which can be used to compute the derivative  $\\frac{\\partial L(w)}{\\partial \\hat y}$. In order to compute the second term $\\frac{\\partial \\hat y}{\\partial w}$, we need to implement a similar `forward()` and `backward()` method in our `Classifier` class.\n","\n","### Backward Pass\n","\n","The backward pass consists of computing the derivative $\\frac{\\partial \\hat y}{\\partial w}$. Again, we can decompose this derivative by the chain rule: For $s = X \\cdot w$ we obtain\n","\n","$$\\frac{\\partial \\hat y}{\\partial w} = \\frac{\\partial \\sigma(s)}{\\partial w} = \\frac{\\partial \\sigma(s)}{\\partial s} \\cdot \\frac{\\partial s}{\\partial w}$$\n","\n","\n","**Hint:** Taking track of the dimensions in higher-dimensional settings can make the task a little bit complicated. Make sure you understand the operations here. If you have difficulties, first try to understand the forward and backward pass if the input is only one sample consisting of $D+1$ features. Then our data matrix has dimension $X \\in \\mathbb{R}^{1 \\times (D+1)}$. After you understood this situation, you can go back to the setting where our data matrix has dimension $X \\in \\mathbb{R}^{N \\times (D+1)}$ and consists of $N$ samples each having $D+1$ features."]},{"cell_type":"markdown","metadata":{"id":"dNrSjQHiqhhE"},"source":["<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>Implement the <code>forward()</code> and <code>backward()</code> pass as well as the <code>sigmoid()</code> function in the <code>Classifier</code> class in <code>exercise_code/networks/classifier.py</code>. Check your implementation using the following testing code.</p>\n","</div>"]},{"cell_type":"code","execution_count":6,"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"9nOojbEKqhhE","executionInfo":{"status":"ok","timestamp":1668285008906,"user_tz":-60,"elapsed":391,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"8ac1da6f-a9ea-4e13-ce88-cf198a76c5fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 1)\n","(2, 3)\n","(3, 1)\n","(2, 1)\n","(3, 1)\n","Sigmoid_Of_Zero passed.\n","Sigmoid_Of_Zero_Array passed.\n","Sigmoid_Of_100 passed.\n","Sigmoid_Of_Array_of_100 passed.\n","Method sigmoid() correctly implemented. Tests passed: 4/4\n","ClassifierForwardTest passed.\n","Method forward() correctly implemented. Tests passed: 1/1\n","ClassifierBackwardTest passed.\n","Method backward() correctly implemented. Tests passed: 1/1\n","Congratulations you have passed all the unit tests!!! Tests passed: 6/6\n","Score: 100/100\n"]}],"source":["from exercise_code.networks.classifier import Classifier\n","from exercise_code.tests.classifier_test import *\n","res = test_classifier(Classifier(num_features=2))"]},{"cell_type":"markdown","metadata":{"id":"RqhDgrV6qhhF"},"source":["## 4. Optimizer and Gradient Descent\n","\n","Previously, we have successfully dealt with the loss function, which is a method of measuring how well our model fits the given data. The idea of the training process is to adjust iteratively the weights of our model in order to minimize the loss function. \n","\n","And this is where the optimizer comes in. In each training step, the optimizer updates the weights of the model w.r.t. the output of the loss function, thereby linking the loss function and model parameters together. The goal is to obtain a model which is accurately predicting the class for a new sample.\n","\n","\n","Any discussion about optimizers needs to begin with the most popular one, and it's called Gradient Descent. This algorithm is used across all types of Machine Learning (and other math problems) to optimize. It's fast, robust, and flexible. Here's how it works:\n","\n","\n","0. Initialize the weights with random values.\n","1. Calculate loss with the current weights and the loss function.\n","2. Calculate the gradient of the loss function w.r.t. the weights.\n","3. Update weights with the corresponding gradient.\n","4. Iteratively perform Step 1 to 3 until converges.\n","\n","The name of the optimizer already hints at the required concept: We use gradients which are very useful for minimizing a function. The gradient of the loss function w.r.t to the weights $w$ of our model tells us how to change our weights $w$ in order to minimize our loss function. \n","\n","The weights are updated each step as follows:\n","$$ w^{(n+1)} = w^{(n)} - \\alpha \\cdot \\frac {dL}{dw}, $$\n","where $ \\frac {dL}{dw}$ is the gradient of your loss function w.r.t. the weights $w$ and $\\alpha$ is the learning rate which is a predefined positive scalar determining the size of the step."]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"xASamjKiqhhF"},"source":["<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>In our model, we will use gradient descent to update the weights. Take a look at the <code>Optimizer</code> class in the file <code>networks/optimizer.py</code>. Your task is now to implement the gradient descent step in the <code>step()</code> method. You can test your implementation by the following testing code.</p>\n","</div>"]},{"cell_type":"code","execution_count":7,"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"o4Xr6rTLqhhF","executionInfo":{"status":"ok","timestamp":1668285021568,"user_tz":-60,"elapsed":2453,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"effb2e18-f895-4f4d-dda7-9b7be039f497"},"outputs":[{"output_type":"stream","name":"stdout","text":["OptimizerStepTest passed.\n","Congratulations you have passed all the unit tests!!! Tests passed: 1/1\n","Score: 100/100\n"]}],"source":["from exercise_code.networks.optimizer import Optimizer\n","from exercise_code.networks.classifier import Classifier\n","from exercise_code.tests.optimizer_test import *\n","TestClassifier=Classifier(num_features=2)\n","TestClassifier.initialize_weights()\n","res = test_optimizer(Optimizer(TestClassifier))"]},{"cell_type":"markdown","metadata":{"id":"7ctNt2c2qhhF"},"source":["## 5. Training\n","\n","We have now implemented all the necessary parts of our training process, namely:\n","- **Classifier Model:** We set up a simple classifier model and you implemented the corresponding ```forward()``` and ```backward()``` methods.\n","- **Loss function:** We chose the Binary Cross Entropy Loss for our model to measure the distance between the prediction of our model and the ground-truth labels. You implemented a forward and backward pass for the loss function.\n","- **Optimizer**: We use the Gradient Descent method to update the weights of our model. Here, you implemented the ```step()``` function which performs the update of the weights. \n","\n","<div class=\"alert alert-success\">\n","    <h3>Task: Check Code</h3>\n","    <p>Before we start our training and put all the parts together, let us shortly talk about the weight initialization. In <code>networks/classifier.py</code> you can check the <code>Classifier</code> class. It contains a method called <code>initialize_weights()</code> that randomly initializes the weights of our classifier model. Later in the lecture, we will learn about more efficient methods to initialize the weights. But for now, a random initialization as it happens in the <code>initialize_weights()</code> method is sufficient.</p>\n","</div>\n","\n","Let's start with our classifier model and look at its performance before any training happened. "]},{"cell_type":"code","execution_count":8,"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"XikyOpGxqhhF","executionInfo":{"status":"ok","timestamp":1668285024450,"user_tz":-60,"elapsed":386,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"4f90bc04-4c05-464d-c310-eed10fa3fa8f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from exercise_code.networks.classifier import Classifier\n","\n","#initialization\n","model = Classifier(num_features=1)\n","model.initialize_weights()\n","\n","y_out = model(X_train)\n","\n","# plot the prediction\n","plt.scatter(X_train, y_train)\n","plot = plt.plot(X_train, y_out, color='r')"]},{"cell_type":"markdown","metadata":{"id":"7K9vztENqhhG"},"source":["As you can see the predictions of our model without any training are very bad. Let's see how the performance improves when we start our training, which means that we update our weights by applying the gradient descent method. The following cell combines the forward and backward passes with the gradient update step and performs a training step for our classifier:\n","\n","<div class=\"alert alert-success\">\n","    <h3>Task: Check Code</h3>\n","    <p>Note that the <code>Classifier</code> class is derived from the more general <code>Network</code> class. It is worth having a look at the basis class <code>Network</code> in the file <code>exercise_code/networks/base_networks.py</code>. We will make use of the <code>__call__()</code> method, which computes the forward and backward pass of your classifier. In a similar manner, we use the <code>__call__()</code> function for our Loss function.</p>\n","</div>\n","\n","The following cell performs training with 400 training steps:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"0S6pxkRlqhhG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668285029242,"user_tz":-60,"elapsed":1678,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"1f4b022d-0bc2-4fd7-cd27-b76b6f1c6cc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  0 --- Average Loss:  0.6930743593449278\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  10 --- Average Loss:  0.6856844628920699\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  20 --- Average Loss:  0.6785721946127877\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  30 --- Average Loss:  0.6716690604572192\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  40 --- Average Loss:  0.6649650362791114\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  50 --- Average Loss:  0.6584536285977679\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  60 --- Average Loss:  0.6521286391068404\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  70 --- Average Loss:  0.6459839885069286\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  80 --- Average Loss:  0.6400137191624556\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  90 --- Average Loss:  0.6342120061926289\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  100 --- Average Loss:  0.6285731670548397\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  110 --- Average Loss:  0.6230916691664224\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  120 --- Average Loss:  0.6177621356800905\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  130 --- Average Loss:  0.6125793495737472\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  140 --- Average Loss:  0.6075382562259669\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  150 --- Average Loss:  0.602633964651409\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  160 --- Average Loss:  0.5978617475678073\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  170 --- Average Loss:  0.593217040459177\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  180 --- Average Loss:  0.5886954397897128\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  190 --- Average Loss:  0.58429270051062\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  200 --- Average Loss:  0.5800047329887852\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  210 --- Average Loss:  0.575827599472449\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  220 --- Average Loss:  0.5717575101954953\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  230 --- Average Loss:  0.5677908192089829\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  240 --- Average Loss:  0.563924020016401\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  250 --- Average Loss:  0.5601537410779817\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  260 --- Average Loss:  0.5564767412393263\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  270 --- Average Loss:  0.5528899051306092\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  280 --- Average Loss:  0.5493902385746965\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  290 --- Average Loss:  0.5459748640355824\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  300 --- Average Loss:  0.542641016132543\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  310 --- Average Loss:  0.5393860372402423\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  320 --- Average Loss:  0.53620737319062\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  330 --- Average Loss:  0.5331025690886532\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  340 --- Average Loss:  0.5300692652509272\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  350 --- Average Loss:  0.5271051932733251\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  360 --- Average Loss:  0.5242081722319374\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  370 --- Average Loss:  0.5213761050194922\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  380 --- Average Loss:  0.5186069748181102\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","Epoch  390 --- Average Loss:  0.5158988417079855\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","\n","Evaluate the trained model on the X_test set: \n","Accuracy: 92.7%\n"]}],"source":["from exercise_code.networks.optimizer import *\n","from exercise_code.networks.classifier import *\n","\n","# Hyperparameter Setting. We will specify the loss function we use, and implement the optimizer we finished in the last step.\n","num_features = X_train.shape[1]\n","\n","# initialization\n","model = Classifier(num_features=num_features)\n","model.initialize_weights()\n","\n","loss_func = BCE() \n","learning_rate = 5e-1  # A hyperparameter\n","loss_history = []\n","opt = Optimizer(model, learning_rate)\n","\n","epochs = 400 # A hyperparameter\n","\n","# Full batch Gradient Descent\n","for i in range(epochs):\n","    \n","    # Enable your model to store the gradient.\n","    model.train()\n","    \n","    # Compute the output and gradients w.r.t weights of your model for the input dataset.\n","    model_forward = model.forward(X_train)\n","    \n","    # Compute the loss and gradients w.r.t output of the model. The begining of the chain rule.\n","    loss, loss_grad = loss_func(model_forward, y_train)\n","\n","    # Send the upstream derivative to the continue the chain rule.\n","    grad = model.backward(loss_grad)\n","    grad /=  X_train.shape[0]   # Compute the average gradient over your batch\n","    \n","    opt.step(grad)\n","    \n","    # Average over the loss of the entire dataset and store it.\n","    average_loss = np.mean(loss)\n","    loss_history.append(average_loss)\n","    if i%10 == 0:\n","        print(\"Epoch \",i,\"--- Average Loss: \", average_loss)\n","    \n","model.eval()\n","model_forward = model(X_test)\n","\n","accuracy = test_accuracy(model_forward, y_test)\n","print(\"\\nEvaluate the trained model on the X_test set: \")\n","print(\"Accuracy: {:.1f}%\".format(accuracy*100))\n"]},{"cell_type":"markdown","metadata":{"id":"lUGl9WUIqhhG"},"source":["We can see that our average loss is decreasing as expected. Let us visualize the average loss and the prediction after our short training:"]},{"cell_type":"code","execution_count":10,"metadata":{"pycharm":{"name":"#%%\n"},"id":"MI_s68hFqhhG","colab":{"base_uri":"https://localhost:8080/","height":559},"executionInfo":{"status":"ok","timestamp":1668285036773,"user_tz":-60,"elapsed":582,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"81d2e902-eaf9-4cd1-c29d-fac1b0809cf4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Plot the loss history to see how it goes after several steps of gradient descent.\n","plt.plot(loss_history, label = 'Train Loss')\n","plt.xlabel('iteration')\n","plt.ylabel('training loss')\n","plt.title('Training Loss history')\n","plt.legend()\n","plt.show()\n","\n","\n","# forward pass\n","\n","y_out = model(X_test)\n","\n","# plot the prediction\n","plt.scatter(X_test, y_test, label = \"Ground Truth\")\n","inds = X_test.argsort(0).flatten()\n","plt.plot(X_test[inds], y_out[inds], color='r', label = \"Prediction\")\n","plt.legend()\n","plt.title('Prediction of your trained model')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"ydiaaBefqhhG"},"source":["This looks pretty good already and our model gets better in explaining the underlying relationship of data.\n","\n","NOTE: Although the testing score is high, the above prediction graph is still somewhat of a poor performance. That is due to the thershold (Look at the implementation of the test_accuracy() function), which classifies the results, or \"logits\", to the binary classes. If the threshold value is $t \\in \\mathbb{R}$, then for $1 \\leq i \\leq N$, we have  \n","$$ g(x_i) = \\begin{cases}\n","    1,& \\text{if }\\, \\hat y_i > t \\\\\n","    0,              & \\text{otherwise}\n","\\end{cases}$$\n","\n","Where $g(x)$ is the classifier function."]},{"cell_type":"markdown","metadata":{"id":"CicWg951qhhH"},"source":["## 6. Solver\n","\n","Now we want to put everything we have learned so far together in an organized and concise way, that provides easy access to train a network/model in your own script/code. The purpose of a solver is mainly to provide an abstraction for all the gritty details behind training your parameters, such as logging your progress, optimizing your model, and handling your data.\n","\n","This part of the exercise will require you to complete the missing code in the ```Solver``` class and to train your model end to end.\n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"U-Mnb90FqhhH"},"source":["<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>Open the file <code>exercise_code/solver.py</code> and have a look at the <code>Solver</code> class. The <code>_step()</code> function is representing one single training step. So when using the Gradient Descent method, it represents one single update step using the Gradient Descent method. Your task is now to finalize this <code>_step()</code> function. You can test your implementation with the testing code included in the following cell.</p>\n","    <p> <b>Hint</b>: The implementation of the <code>_step()</code> function is very similar to the implementation of a training step as we observed above. You may have a look at that part first. </p>\n","</div>"]},{"cell_type":"code","execution_count":11,"metadata":{"pycharm":{"name":"#%%\n"},"id":"86bP7fQzqhhH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668285045330,"user_tz":-60,"elapsed":1651,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"a7ef06c3-1c2f-4cd2-e7e3-2778a0a5fb9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","SolverStepTest passed.\n","Congratulations you have passed all the unit tests!!! Tests passed: 1/1\n","Score: 100/100\n"]}],"source":["from exercise_code.solver import Solver\n","from exercise_code.networks.classifier import Classifier\n","from exercise_code.tests.solver_tests import *\n","weights = np.array([[0.1],[0.1]])\n","TestClassifier = Classifier(num_features=1)\n","TestClassifier.initialize_weights(weights)\n","learning_rate = 5e-1\n","data = {'X_train': X_train, 'y_train': y_train,\n","        'X_val': X_val, 'y_val': y_val}\n","loss = BCE()\n","solver = Solver(TestClassifier,data,loss,learning_rate,verbose=True)\n","\n","res = test_solver(solver)"]},{"cell_type":"markdown","metadata":{"id":"2t0MtesIqhhH"},"source":["After having successfully implemented the `step()` function in the `Optimizer` class, let us now train our classifier. We train our model with a learning rate $ \\lambda = 0.1$ and with 25000 epochs. Your model should reach an accuracy which is higher than 85%. "]},{"cell_type":"code","execution_count":12,"metadata":{"pycharm":{"name":"#%%\n"},"id":"JU9zzcGJqhhH","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1668285086291,"user_tz":-60,"elapsed":38105,"user":{"displayName":"Wang Yuqing","userId":"10721270073886287944"}},"outputId":"323eb0c0-f707-4ed0-c08c-e79f8b230595"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy BEFORE training 58.2%\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(Epoch 10000 / 25000) train loss: 0.366036; val_loss: 0.376833\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n","(533, 1)\n","(533, 2)\n","(2, 1)\n","(533, 1)\n","(2, 1)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-dc2b9be75c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Train the model, and look at the results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/i2dl/exercise_04/exercise_code/solver.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Check the performance of the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/i2dl/exercise_04/exercise_code/solver.py\u001b[0m in \u001b[0;36mcheck_loss\u001b[0;34m(self, validation)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mmodel_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/i2dl/exercise_04/exercise_code/networks/base_networks.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m\"\"\"takes data points X in train mode, and data X and output y in eval mode\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/i2dl/exercise_04/exercise_code/networks/classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;31m# self.cache = y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# self.cache = np.concatenate((X, y), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/i2dl/exercise_04/exercise_code/networks/classifier.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from exercise_code.solver import Solver\n","from exercise_code.networks.utils import test_accuracy\n","from exercise_code.networks.classifier import Classifier\n","# Select the number of features, you want your task to train on.\n","num_features = X_train.shape[1]\n","\n","\n","# initialize model and weights\n","model = Classifier(num_features=num_features)\n","model.initialize_weights()\n","\n","y_out = model(X_test)\n","\n","accuracy = test_accuracy(y_out, y_test)\n","print(\"Accuracy BEFORE training {:.1f}%\".format(accuracy*100))\n","\n","\n","if np.shape(X_test)[1]==1:\n","    plt.scatter(X_test, y_test, label = \"Ground Truth\")\n","    inds = X_test.flatten().argsort(0)\n","    plt.plot(X_test[inds], y_out[inds], color='r', label = \"Prediction\")\n","    plt.legend()\n","    plt.show()\n","\n","data = {'X_train': X_train, 'y_train': y_train,\n","        'X_val': X_val, 'y_val': y_val}\n","\n","#We use the BCE loss\n","loss = BCE()\n","\n","# Please use these hyperparmeter as we also use them later in the evaluation\n","learning_rate = 1e-1\n","epochs = 25000\n","\n","# Setup for the actual solver that's going to do the job of training\n","# the model on the given data. set 'verbose=True' to see real time \n","# progress of the training. \n","#\n","# Note: Too many epochs will result in OVERFITING - the training loss \n","# will shrink towards zero, while the perfromance on the test set is actually worsened. \n","\n","solver = Solver(model, \n","                data, \n","                loss,\n","                learning_rate, \n","                verbose=True, \n","                print_every = 1000)\n","\n","# Train the model, and look at the results.\n","solver.train(epochs)\n","\n","\n","# Test final performance\n","y_out = model(X_test)\n","accuracy = test_accuracy(y_out, y_test)\n","print(\"Accuracy AFTER training {:.1f}%\".format(accuracy*100))"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"antu6iFjqhhH"},"source":["During the training process losses in each epoch are stored in the lists `solver.train_loss_history` and `solver.val_loss_history`. We can use them to plot the training result easily."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"kq9wiQeyqhhH"},"outputs":[],"source":["plt.plot(solver.val_loss_history, label = \"Validation Loss\")\n","plt.plot(solver.train_loss_history, label = \"Train Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend() \n","plt.title('Training and Validation Loss')\n","plt.show() \n","\n","\n","if np.shape(X_test)[1]==1:\n","\n","    plt.scatter(X_test, y_test, label = \"Ground Truth\")\n","    inds = X_test.argsort(0).flatten()\n","    plt.plot(X_test[inds], y_out[inds], color='r', label = \"Prediction\")\n","    plt.legend()\n","    plt.title('Prediction of your trained model')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"L6WAbrezqhhI"},"source":["## 7. Save your BCE Loss, Classifier and Solver for Submission\n","\n","Your model should be trained now and able to predict whether a house is expensive or not. Hooooooray, you trained your very first model! The model will be saved as a pickle file to `models/simple_classifier.p`."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"OA_d5qSeqhhI"},"outputs":[],"source":["from exercise_code.tests import save_pickle\n","\n","save_pickle(\n","    data_dict={\n","        \"BCE_class\": BCE,\n","        \"Classifier_class\": Classifier,\n","        \"Optimizer\": Optimizer,\n","        \"Solver_class\": Solver\n","    },\n","    file_name=\"simple_classifier.p\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"ZMHFrSnwqhhI"},"source":["# Submission Instructions\n","\n","Now, that you have completed the necessary parts in the notebook, you can go on and submit your files.\n","\n","1. Go on [our submission page](https://i2dl.vc.in.tum.de/), register for an account and login. We use your matriculation number and send an email with the login details to the mail account associated. When in doubt, login into tum-online and check your mails there. You will get an id which we need in the next step.\n","2. Log into [our submission page](https://i2dl.vc.in.tum.de/) with your account details and upload the zip file.\n","3. Your submission will be evaluated by our system and you will get feedback about the performance of it. You will get an email with your score as well as a message if you have surpassed the threshold.\n","4. Within the working period, you can submit as many solutions as you want to get the best possible score."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skc_JWtLqhhI"},"outputs":[],"source":["from exercise_code.submit import submit_exercise\n","\n","submit_exercise('../output/exercise_04')"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"QI_7ABanqhhI"},"source":["# Submission Goals\n","\n","For this exercise we only test your implementations which are tested throughout the notebook.  In total we have 10 test cases, where you are required to complete at least 8. Here is an overview split among the notebook:\n","\n","- Goal: \n","    - To implement: \n","        1. `exercise_code/networks/loss.py`: `forward()`, `backward()`\n","        2. `exercise_code/networks/classifier.py`: `forward()`, `backward()`, `sigmoid()`\n","        3. `exercise_code/networks/optimizer.py`: `step()`\n","        4. `exercise_code/solver.py`: `_step()`\n","\n","    - Test cases:\n","      1. Does `forward()` of `BCE` return the correct value?\n","      2. Does `backward()` of `BCE` return the correct value?\n","      3. Does `sigmoid()` of `Classifier` return the correct value when `x=0`?\n","      4. Does `sigmoid()` of `Classifier` return the correct value when `x=np.array([0,0,0,0,0])`?\n","      5. Does `sigmoid()` of `Classifier` return the correct value when `x=100`?\n","      6. Does `sigmoid()` of `Classifier` return the correct value when `x=np.asarray([100, 100, 100, 100, 100])`?\n","      7. Does `forward()` of `Classifier` return the correct value?\n","      8. Does `backward()` of `Classifier` return the correct value?\n","      9. Does `Optimizer` update the model parameter correctly?\n","      10. Does `Solver` update the model parameter correctly?\n","    \n","<br />\n","\n","- Reachable points [0, 100]: 0 if not implemented, 100 if all tests passed, 10 per passed test\n","- Threshold to pass the exercise: 80\n","- Submission start: __November 10, 2022__\n","- Submission deadline: __November 16, 2022 23.59__\n","- You can make multiple submissions until the deadline. Your __best submission__ will be considered for bonus."]},{"cell_type":"markdown","metadata":{"id":"nMhJm-MZqhhI"},"source":["# [Exercise Review](https://docs.google.com/forms/d/e/1FAIpQLScwZArz6ogLqBEj--ItB6unKcv0u9gWLj8bspeiATrDnFH9hA/viewform)\n","\n","We are always interested in your opinion. Now that you have finished this exercise, we would like you to give us some feedback about the time required to finish the submission and/or work through the notebooks. Please take the short time to fill out our [review form](https://docs.google.com/forms/d/e/1FAIpQLScwZArz6ogLqBEj--ItB6unKcv0u9gWLj8bspeiATrDnFH9hA/viewform) for this exercise so that we can do better next time! :)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('i2dl')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"54970da6898dad277dbf355945c2dee7f942d2a31ec1fc1455b6d4f552d07b83"}},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}